#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass report
\begin_preamble
\usepackage{framed}
\usepackage[outerbars]{changebar}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding utf8
\fontencoding default
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks false
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref section
\pdf_pdfusetitle false
\papersize a4paper
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Notes
\end_layout

\begin_layout Author
LÃ©o
\end_layout

\begin_layout Standard
While being self-sufficient, those notes focus on the recent results in
 optimization and don't pretend to be an exhaustive review of optimization
 methods.
\end_layout

\begin_layout Chapter
Music generation
\end_layout

\begin_layout Chapter
Orchestral inference
\end_layout

\begin_layout Section
Projective symbolic orchestration
\end_layout

\begin_layout Subsection
Factored Gated Conditional RBM
\end_layout

\begin_layout Standard
The two next steps should be easy to implement and imply important changes
 : 
\end_layout

\begin_layout Itemize
take dynamics into consideration 
\end_layout

\begin_layout Itemize
event level 
\end_layout

\begin_layout Standard
Other leads should be quickly investigated, although not spending to much
 time on it 
\end_layout

\begin_layout Itemize
Greatly increase the number of factor units.
 It should greatly improve the 
\emph on
expressiveness
\emph default
 of the network.
 
\end_layout

\begin_layout Section
Multi-modal signal/symbolic networks #1 : based on a mapping to and from
 the embedding space
\end_layout

\begin_layout Standard
The idea is to build a system where orchestration is controlled in real-time
 by a set of faders which in they turn control some spectral features.
 It would be a purely generative system that would not rely on a piano score,
 but instead would be more an ambient generator (I imagine the result as
 
\emph on
sound layers
\emph default
).
\end_layout

\begin_layout Subsection
Learning step
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /Users/leo/Documents/Mega_sync/Travail/Recherche/GitHub_Aciditeam/documents/figures/Multimodal/siamese_net_projection.pdf
	width 47text%

\end_inset


\begin_inset Graphics
	filename /Users/leo/Documents/Mega_sync/Travail/Recherche/GitHub_Aciditeam/documents/figures/Multimodal/siamese_net_backprop.pdf
	width 47text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Embedding of different representations in a common modal space.
 This is the encoding step
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The learning step rely on an orchestral database composed of the scores
 (xml preferably, midi otherwise) and a recording.
 Each track is divided in (short) time frames (both score and recording).
 The two Siamese networks respectively receive in input a symbolic frame
 and its corresponding signal frame (or its FFT, or any other perceptually
 relevant transformation).
 The training is then divided in two steps 
\end_layout

\begin_layout Enumerate
unsupervised step, in order to learn relevant features in the last layer
 
\end_layout

\begin_layout Enumerate
supervised step in order to force the output of the two networks to be close
 in a metric space.
 
\end_layout

\begin_layout Standard
The structure of the two networks have to be determined (recurrent nets
 or simple deep architectures ? Stacked memory ?), but the first step would
 rely on state of the art methods in automatic features extraction.
 A first remark for the second step is that it requires the two networks
 to have the same number of output units 
\begin_inset Formula $|O|$
\end_inset

.
 Those two sets of output units define two points in 
\begin_inset Formula $\left[0,1\right]{|O|}$
\end_inset

 (or 
\begin_inset Formula $\mathbb{R}_{+}^{|O|}$
\end_inset

 if we use a different type of unit for the output ?).
 The distance between those two points then define an error function that
 we can differentiate in order to fine-tuned the two networks with back-propagat
ion.
\end_layout

\begin_layout Subsubsection
Signal network
\end_layout

\begin_layout Itemize
Attention models ? Instead of a classic convnet on spectro
\end_layout

\begin_layout Itemize
Which pre-processing ? Cochlear transform
\end_layout

\begin_layout Subsubsection
Symbolic network
\end_layout

\begin_layout Itemize
Can't use Skip-thought vectors : a solution would have been to encode all
 the possible vectors in a one-hot representation and then encode them through
 a predictive task, but the one-hot representation would involve vectors
 of size 
\begin_inset Formula $\begin{pmatrix}88\\
1
\end{pmatrix}+\begin{pmatrix}88\\
2
\end{pmatrix}+\begin{pmatrix}88\\
3
\end{pmatrix}+\begin{pmatrix}88\\
4
\end{pmatrix}=2.445.542$
\end_inset

 for a single instrument and at least 
\begin_inset Formula $\begin{pmatrix}450\\
1
\end{pmatrix}+\begin{pmatrix}450\\
2
\end{pmatrix}+\begin{pmatrix}450\\
3
\end{pmatrix}+\begin{pmatrix}450\\
4
\end{pmatrix}=1.7\times10^{9}$
\end_inset

 for an orchestral representation.
\end_layout

\begin_layout Itemize
Bi-dimensional RNN (hexahedria) ? Seems to complex for an orchestral representat
ion.
\end_layout

\begin_deeper
\begin_layout Itemize
(Deep)-LSTM -> best solution so far I think.
 Combined with a clever representation (braids) ?
\end_layout

\end_deeper
\begin_layout Subsection
Generation phase
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /Users/leo/Documents/Mega_sync/Travail/Recherche/GitHub_Aciditeam/documents/figures/Multimodal/siamese_net_generation.pdf
	width 97line%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Generation step in the Siamese network.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A fader is associated to each dimensions of our 
\emph on
projection
\emph default
 space (space defined by the output units).
 The position of each fader then define the coordinate of the synthesis
 point.
 We associate to each output unit the value of each coordinate of the synthesis
 point and back-propagate those values in the 
\emph on
symbolic
\emph default
 network to obtain the orchestration and in the 
\emph on
spectral
\emph default
 network to observe the ideal signal/spectrogram (probably not totally the
 same that the one corresponding to the symbolic score played).
\end_layout

\begin_layout Subsection
Unsolved questions
\end_layout

\begin_layout Itemize
Input for the 
\emph on
spectral/signal
\emph default
 network 
\end_layout

\begin_layout Itemize
Which architecture ? (recurrent nets or simple deep architectures ? Stacked
 memory, Deep LSTM ?) 
\end_layout

\begin_layout Itemize
Which type of input 
\series bold
and
\series default
 output units ? 
\end_layout

\begin_layout Itemize
How to deal with continuity of orchestration ? A lead could be to define
 Siamese network for past frames and force recent past to be close to the
 actual frame in the projection space.
 
\end_layout

\begin_layout Subsection
Application
\end_layout

\begin_layout Itemize
Generating orchestration 
\end_layout

\begin_layout Itemize
audio to score.
 Plus it gives a good evaluation framework.
\end_layout

\begin_layout Section
Multi-modal signal/symbolic networks #2 : Encoder/Decoder
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "kiros2014unifying"

\end_inset

 Useful for two reasons 
\end_layout

\begin_layout Itemize
Automatically classify orchestral effects (encoding phase)
\end_layout

\begin_layout Itemize
Generating the score of a spectral frame (decoding phase)
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "/Users/leo/Documents/Mega_sync/Travail/Recherche/GitHub_Aciditeam/documents/state-of-art/Deep_learning/deeplearning"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
