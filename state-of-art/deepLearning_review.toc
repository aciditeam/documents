\select@language {english}
\contentsline {section}{\numberline {1}Introduction}{2}{section.1}
\contentsline {subsection}{\numberline {1.1}Advantages of deep architectures}{3}{subsection.1.1}
\contentsline {subsection}{\numberline {1.2}Feature learning}{3}{subsection.1.2}
\contentsline {subsection}{\numberline {1.3}Manifold and complexity}{4}{subsection.1.3}
\contentsline {subsection}{\numberline {1.4}Application to audio}{4}{subsection.1.4}
\contentsline {subsubsection}{\numberline {1.4.1}Time scales problem}{5}{subsubsection.1.4.1}
\contentsline {section}{\numberline {2}Architectures}{5}{section.2}
\contentsline {subsection}{\numberline {2.1}Logistic regression}{5}{subsection.2.1}
\contentsline {paragraph}{\nonumberline Properties}{6}{section*.2}
\contentsline {subsection}{\numberline {2.2}Neural networks}{6}{subsection.2.2}
\contentsline {subsubsection}{\numberline {2.2.1}Artificial neuron}{6}{subsubsection.2.2.1}
\contentsline {subsubsection}{\numberline {2.2.2}Various computation units}{6}{subsubsection.2.2.2}
\contentsline {paragraph}{\nonumberline Sigmoid}{6}{section*.3}
\contentsline {paragraph}{\nonumberline Hyperbolic tangent}{6}{section*.4}
\contentsline {paragraph}{\nonumberline Gaussian}{7}{section*.5}
\contentsline {paragraph}{\nonumberline Rectified linear}{7}{section*.6}
\contentsline {paragraph}{\nonumberline Others}{7}{section*.7}
\contentsline {subsubsection}{\numberline {2.2.3}Multi-layer neural networks}{7}{subsubsection.2.2.3}
\contentsline {subsubsection}{\numberline {2.2.4}Learning algorithm}{8}{subsubsection.2.2.4}
\contentsline {subsubsection}{\numberline {2.2.5}Gradient descent}{9}{subsubsection.2.2.5}
\contentsline {subsection}{\numberline {2.3}Difficulty of training deep architectures}{9}{subsection.2.3}
\contentsline {subsection}{\numberline {2.4}Unsupervised (self-taught) learning}{9}{subsection.2.4}
\contentsline {subsection}{\numberline {2.5}Greedy layer-wise training}{10}{subsection.2.5}
\contentsline {subsection}{\numberline {2.6}Reconstruction goal}{10}{subsection.2.6}
\contentsline {section}{\numberline {3}Single-layer modules}{11}{section.3}
\contentsline {subsection}{\numberline {3.1}Auto-encoders}{11}{subsection.3.1}
\contentsline {subsubsection}{\numberline {3.1.1}Basic auto-encoder}{11}{subsubsection.3.1.1}
\contentsline {subsubsection}{\numberline {3.1.2}Regularized auto-encoders}{13}{subsubsection.3.1.2}
\contentsline {subsubsection}{\numberline {3.1.3}Sparse auto-encoders}{13}{subsubsection.3.1.3}
\contentsline {subsubsection}{\numberline {3.1.4}Denoising auto-encoders}{14}{subsubsection.3.1.4}
\contentsline {subsubsection}{\numberline {3.1.5}Contractive auto-encoders}{15}{subsubsection.3.1.5}
\contentsline {subsubsection}{\numberline {3.1.6}Linear decoders}{15}{subsubsection.3.1.6}
\contentsline {subsection}{\numberline {3.2}Restricted Boltzmann Machine}{16}{subsection.3.2}
\contentsline {subsubsection}{\numberline {3.2.1}Different types of unit}{17}{subsubsection.3.2.1}
\contentsline {paragraph}{\nonumberline Sigmo\IeC {\"\i }d and softmax units}{18}{section*.8}
\contentsline {paragraph}{\nonumberline Gaussian units}{18}{section*.9}
\contentsline {paragraph}{\nonumberline Binomial units}{18}{section*.10}
\contentsline {paragraph}{\nonumberline Rectified linear units}{18}{section*.11}
\contentsline {subsubsection}{\numberline {3.2.2}Conditional RBM}{18}{subsubsection.3.2.2}
\contentsline {subsubsection}{\numberline {3.2.3}Temporal RBM}{19}{subsubsection.3.2.3}
\contentsline {subsubsection}{\numberline {3.2.4}Gated RBM}{20}{subsubsection.3.2.4}
\contentsline {subsubsection}{\numberline {3.2.5}Factored RBM}{20}{subsubsection.3.2.5}
\contentsline {section}{\numberline {4}Deep architectures}{20}{section.4}
\contentsline {subsection}{\numberline {4.1}Stacked auto-encoders}{20}{subsection.4.1}
\contentsline {subsubsection}{\numberline {4.1.1}Pre-training stacked autoencoders}{21}{subsubsection.4.1.1}
\contentsline {subsubsection}{\numberline {4.1.2}Fine-tuning stacked auto-encoders}{21}{subsubsection.4.1.2}
\contentsline {subsection}{\numberline {4.2}Deep Belief Networks}{21}{subsection.4.2}
\contentsline {subsection}{\numberline {4.3}Deep Boltzmann Machine}{24}{subsection.4.3}
\contentsline {subsection}{\numberline {4.4}Temporal models}{26}{subsection.4.4}
\contentsline {subsubsection}{\numberline {4.4.1}Recurrent Neural Network}{26}{subsubsection.4.4.1}
\contentsline {subsubsection}{\numberline {4.4.2}Convolution and pooling}{27}{subsubsection.4.4.2}
\contentsline {subsubsection}{\numberline {4.4.3}Temporal coherence}{27}{subsubsection.4.4.3}
\contentsline {subsubsection}{\numberline {4.4.4}Comparison}{27}{subsubsection.4.4.4}
\contentsline {subsubsection}{\numberline {4.4.5}Summary}{27}{subsubsection.4.4.5}
\contentsline {section}{\numberline {5}Other models}{28}{section.5}
\contentsline {subsection}{\numberline {5.1}Convolutional Neural Networks}{28}{subsection.5.1}
\contentsline {subsubsection}{\numberline {5.1.1}Sparse connectivity}{28}{subsubsection.5.1.1}
\contentsline {subsubsection}{\numberline {5.1.2}Convolutions}{28}{subsubsection.5.1.2}
\contentsline {subsubsection}{\numberline {5.1.3}Shared weights}{29}{subsubsection.5.1.3}
\contentsline {subsubsection}{\numberline {5.1.4}Feature maps}{29}{subsubsection.5.1.4}
\contentsline {subsubsection}{\numberline {5.1.5}Max pooling}{30}{subsubsection.5.1.5}
\contentsline {subsubsection}{\numberline {5.1.6}Tying the full model together}{30}{subsubsection.5.1.6}
\contentsline {subsubsection}{\numberline {5.1.7}Choosing hyperparameters}{31}{subsubsection.5.1.7}
\contentsline {paragraph}{\nonumberline Filters}{31}{section*.12}
\contentsline {paragraph}{\nonumberline Pooling}{31}{section*.13}
\contentsline {subsection}{\numberline {5.2}Sparse coding}{31}{subsection.5.2}
\contentsline {subsubsection}{\numberline {5.2.1}Probabilistic interpretation}{31}{subsubsection.5.2.1}
\contentsline {subsubsection}{\numberline {5.2.2}Autoencoder interpretation}{32}{subsubsection.5.2.2}
\contentsline {subsubsection}{\numberline {5.2.3}Topographic sparse coding}{33}{subsubsection.5.2.3}
\contentsline {subsection}{\numberline {5.3}Deconvolutional networks}{33}{subsection.5.3}
\contentsline {subsubsection}{\numberline {5.3.1}Single layer}{33}{subsubsection.5.3.1}
\contentsline {paragraph}{\nonumberline Gaussian unpooling}{34}{section*.14}
\contentsline {paragraph}{\nonumberline Cost function}{34}{section*.15}
\contentsline {paragraph}{\nonumberline Single layer inference}{34}{section*.16}
\contentsline {subsubsection}{\numberline {5.3.2}Multi-layer stacking}{34}{subsubsection.5.3.2}
\contentsline {section}{\numberline {6}Applying deep learning}{34}{section.6}
\contentsline {subsection}{\numberline {6.1}Preprocessing}{34}{subsection.6.1}
\contentsline {subsubsection}{\numberline {6.1.1}PCA}{35}{subsubsection.6.1.1}
\contentsline {subsubsection}{\numberline {6.1.2}Stationarity}{35}{subsubsection.6.1.2}
\contentsline {subsubsection}{\numberline {6.1.3}Whitening}{35}{subsubsection.6.1.3}
\contentsline {subsubsection}{\numberline {6.1.4}ZCA Whitening}{35}{subsubsection.6.1.4}
\contentsline {subsubsection}{\numberline {6.1.5}Pre-processing parameters}{36}{subsubsection.6.1.5}
\contentsline {subsection}{\numberline {6.2}Hyper-parameters analysis}{36}{subsection.6.2}
\contentsline {subsubsection}{\numberline {6.2.1}The learning rate}{36}{subsubsection.6.2.1}
\contentsline {subsubsection}{\numberline {6.2.2}Initial weights values}{36}{subsubsection.6.2.2}
\contentsline {subsubsection}{\numberline {6.2.3}Momentum}{36}{subsubsection.6.2.3}
\contentsline {subsubsection}{\numberline {6.2.4}Weight decay}{36}{subsubsection.6.2.4}
\contentsline {subsubsection}{\numberline {6.2.5}Held-out validation data}{36}{subsubsection.6.2.5}
\contentsline {subsubsection}{\numberline {6.2.6}Encouraging sparse hidden activities}{36}{subsubsection.6.2.6}
\contentsline {subsubsection}{\numberline {6.2.7}Number of hidden units}{37}{subsubsection.6.2.7}
\contentsline {subsubsection}{\numberline {6.2.8}Varieties of contrastive divergence}{37}{subsubsection.6.2.8}
\contentsline {subsubsection}{\numberline {6.2.9}The size of a mini-batch}{37}{subsubsection.6.2.9}
\contentsline {subsection}{\numberline {6.3}Parameter tuning search}{38}{subsection.6.3}
\contentsline {subsection}{\numberline {6.4}Monitoring and displaying}{38}{subsection.6.4}
\contentsline {subsubsection}{\numberline {6.4.1}Monitoring the learning}{38}{subsubsection.6.4.1}
\contentsline {paragraph}{\nonumberline Histograms}{38}{section*.17}
\contentsline {paragraph}{\nonumberline Specificity of the features}{38}{section*.18}
\contentsline {paragraph}{\nonumberline Weights display}{38}{section*.19}
\contentsline {subsubsection}{\numberline {6.4.2}t-distributed Stochastic Neighbor Embedding (t-SNE)}{38}{subsubsection.6.4.2}
\contentsline {section}{\numberline {7}Applications}{38}{section.7}
\contentsline {section}{\numberline {8}Future directions}{39}{section.8}
\contentsline {section}{\numberline {9}General infos}{40}{section.9}
