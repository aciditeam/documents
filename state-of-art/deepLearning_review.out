\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Advantages of deep architectures}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Feature learning}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Manifold and complexity}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{Application to audio}{section.1}% 5
\BOOKMARK [3][-]{subsubsection.1.4.1}{Time scales problem}{subsection.1.4}% 6
\BOOKMARK [1][-]{section.2}{Architectures}{}% 7
\BOOKMARK [2][-]{subsection.2.1}{Logistic regression}{section.2}% 8
\BOOKMARK [2][-]{subsection.2.2}{Neural networks}{section.2}% 9
\BOOKMARK [3][-]{subsubsection.2.2.1}{Artificial neuron}{subsection.2.2}% 10
\BOOKMARK [3][-]{subsubsection.2.2.2}{Various computation units}{subsection.2.2}% 11
\BOOKMARK [3][-]{subsubsection.2.2.3}{Multi-layer neural networks}{subsection.2.2}% 12
\BOOKMARK [3][-]{subsubsection.2.2.4}{Learning algorithm}{subsection.2.2}% 13
\BOOKMARK [3][-]{subsubsection.2.2.5}{Gradient descent}{subsection.2.2}% 14
\BOOKMARK [2][-]{subsection.2.3}{Difficulty of training deep architectures}{section.2}% 15
\BOOKMARK [2][-]{subsection.2.4}{Unsupervised \(self-taught\) learning}{section.2}% 16
\BOOKMARK [2][-]{subsection.2.5}{Greedy layer-wise training}{section.2}% 17
\BOOKMARK [2][-]{subsection.2.6}{Reconstruction goal}{section.2}% 18
\BOOKMARK [1][-]{section.3}{Single-layer modules}{}% 19
\BOOKMARK [2][-]{subsection.3.1}{Auto-encoders}{section.3}% 20
\BOOKMARK [3][-]{subsubsection.3.1.1}{Basic auto-encoder}{subsection.3.1}% 21
\BOOKMARK [3][-]{subsubsection.3.1.2}{Regularized auto-encoders}{subsection.3.1}% 22
\BOOKMARK [3][-]{subsubsection.3.1.3}{Sparse auto-encoders}{subsection.3.1}% 23
\BOOKMARK [3][-]{subsubsection.3.1.4}{Denoising auto-encoders}{subsection.3.1}% 24
\BOOKMARK [3][-]{subsubsection.3.1.5}{Contractive auto-encoders}{subsection.3.1}% 25
\BOOKMARK [3][-]{subsubsection.3.1.6}{Linear decoders}{subsection.3.1}% 26
\BOOKMARK [2][-]{subsection.3.2}{Restricted Boltzmann Machine}{section.3}% 27
\BOOKMARK [3][-]{subsubsection.3.2.1}{Different types of unit}{subsection.3.2}% 28
\BOOKMARK [3][-]{subsubsection.3.2.2}{Conditional RBM}{subsection.3.2}% 29
\BOOKMARK [3][-]{subsubsection.3.2.3}{Temporal RBM}{subsection.3.2}% 30
\BOOKMARK [3][-]{subsubsection.3.2.4}{Gated RBM}{subsection.3.2}% 31
\BOOKMARK [3][-]{subsubsection.3.2.5}{Factored RBM}{subsection.3.2}% 32
\BOOKMARK [1][-]{section.4}{Deep architectures}{}% 33
\BOOKMARK [2][-]{subsection.4.1}{Stacked auto-encoders}{section.4}% 34
\BOOKMARK [3][-]{subsubsection.4.1.1}{Pre-training stacked autoencoders}{subsection.4.1}% 35
\BOOKMARK [3][-]{subsubsection.4.1.2}{Fine-tuning stacked auto-encoders}{subsection.4.1}% 36
\BOOKMARK [2][-]{subsection.4.2}{Deep Belief Networks}{section.4}% 37
\BOOKMARK [2][-]{subsection.4.3}{Deep Boltzmann Machine}{section.4}% 38
\BOOKMARK [2][-]{subsection.4.4}{Temporal models}{section.4}% 39
\BOOKMARK [3][-]{subsubsection.4.4.1}{Recurrent Neural Network}{subsection.4.4}% 40
\BOOKMARK [3][-]{subsubsection.4.4.2}{Convolution and pooling}{subsection.4.4}% 41
\BOOKMARK [3][-]{subsubsection.4.4.3}{Temporal coherence}{subsection.4.4}% 42
\BOOKMARK [3][-]{subsubsection.4.4.4}{Comparison}{subsection.4.4}% 43
\BOOKMARK [3][-]{subsubsection.4.4.5}{Summary}{subsection.4.4}% 44
\BOOKMARK [1][-]{section.5}{Other models}{}% 45
\BOOKMARK [2][-]{subsection.5.1}{Convolutional Neural Networks}{section.5}% 46
\BOOKMARK [3][-]{subsubsection.5.1.1}{Sparse connectivity}{subsection.5.1}% 47
\BOOKMARK [3][-]{subsubsection.5.1.2}{Convolutions}{subsection.5.1}% 48
\BOOKMARK [3][-]{subsubsection.5.1.3}{Shared weights}{subsection.5.1}% 49
\BOOKMARK [3][-]{subsubsection.5.1.4}{Feature maps}{subsection.5.1}% 50
\BOOKMARK [3][-]{subsubsection.5.1.5}{Max pooling}{subsection.5.1}% 51
\BOOKMARK [3][-]{subsubsection.5.1.6}{Tying the full model together}{subsection.5.1}% 52
\BOOKMARK [3][-]{subsubsection.5.1.7}{Choosing hyperparameters}{subsection.5.1}% 53
\BOOKMARK [2][-]{subsection.5.2}{Sparse coding}{section.5}% 54
\BOOKMARK [3][-]{subsubsection.5.2.1}{Probabilistic interpretation}{subsection.5.2}% 55
\BOOKMARK [3][-]{subsubsection.5.2.2}{Autoencoder interpretation}{subsection.5.2}% 56
\BOOKMARK [3][-]{subsubsection.5.2.3}{Topographic sparse coding}{subsection.5.2}% 57
\BOOKMARK [2][-]{subsection.5.3}{Deconvolutional networks}{section.5}% 58
\BOOKMARK [3][-]{subsubsection.5.3.1}{Single layer}{subsection.5.3}% 59
\BOOKMARK [3][-]{subsubsection.5.3.2}{Multi-layer stacking}{subsection.5.3}% 60
\BOOKMARK [1][-]{section.6}{Applying deep learning}{}% 61
\BOOKMARK [2][-]{subsection.6.1}{Preprocessing}{section.6}% 62
\BOOKMARK [3][-]{subsubsection.6.1.1}{PCA}{subsection.6.1}% 63
\BOOKMARK [3][-]{subsubsection.6.1.2}{Stationarity}{subsection.6.1}% 64
\BOOKMARK [3][-]{subsubsection.6.1.3}{Whitening}{subsection.6.1}% 65
\BOOKMARK [3][-]{subsubsection.6.1.4}{ZCA Whitening}{subsection.6.1}% 66
\BOOKMARK [3][-]{subsubsection.6.1.5}{Pre-processing parameters}{subsection.6.1}% 67
\BOOKMARK [2][-]{subsection.6.2}{Hyper-parameters analysis}{section.6}% 68
\BOOKMARK [3][-]{subsubsection.6.2.1}{The learning rate}{subsection.6.2}% 69
\BOOKMARK [3][-]{subsubsection.6.2.2}{Initial weights values}{subsection.6.2}% 70
\BOOKMARK [3][-]{subsubsection.6.2.3}{Momentum}{subsection.6.2}% 71
\BOOKMARK [3][-]{subsubsection.6.2.4}{Weight decay}{subsection.6.2}% 72
\BOOKMARK [3][-]{subsubsection.6.2.5}{Held-out validation data}{subsection.6.2}% 73
\BOOKMARK [3][-]{subsubsection.6.2.6}{Encouraging sparse hidden activities}{subsection.6.2}% 74
\BOOKMARK [3][-]{subsubsection.6.2.7}{Number of hidden units}{subsection.6.2}% 75
\BOOKMARK [3][-]{subsubsection.6.2.8}{Varieties of contrastive divergence}{subsection.6.2}% 76
\BOOKMARK [3][-]{subsubsection.6.2.9}{The size of a mini-batch}{subsection.6.2}% 77
\BOOKMARK [2][-]{subsection.6.3}{Parameter tuning search}{section.6}% 78
\BOOKMARK [2][-]{subsection.6.4}{Monitoring and displaying}{section.6}% 79
\BOOKMARK [3][-]{subsubsection.6.4.1}{Monitoring the learning}{subsection.6.4}% 80
\BOOKMARK [3][-]{subsubsection.6.4.2}{t-distributed Stochastic Neighbor Embedding \(t-SNE\)}{subsection.6.4}% 81
\BOOKMARK [1][-]{section.7}{Applications}{}% 82
\BOOKMARK [1][-]{section.8}{Future directions}{}% 83
\BOOKMARK [1][-]{section.9}{General infos}{}% 84
